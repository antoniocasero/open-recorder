---
phase: 01-transcription-mvp
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src-tauri/src/commands/transcription.rs
  - src-tauri/src/lib.rs
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Backend can transcribe audio files using OpenAI Whisper API"
    - "Transcript saved as .txt file alongside original audio"
    - "API key read from environment variable"
  artifacts:
    - path: "src-tauri/src/commands/transcription.rs"
      provides: "transcribe_audio command implementation"
      min_lines: 80
    - path: "src-tauri/src/lib.rs"
      provides: "Command registration"
      contains: "transcribe_audio"
  key_links:
    - from: "src-tauri/src/commands/transcription.rs"
      to: "OPENAI_API_KEY environment variable"
      via: "std::env::var"
      pattern: "OPENAI_API_KEY"
    - from: "src-tauri/src/commands/transcription.rs"
      to: "async-openai crate"
      via: "use async_openai"
      pattern: "use async_openai"
    - from: "src-tauri/src/commands/transcription.rs"
      to: "sidecar .txt file"
      via: "std::fs::write"
      pattern: "with_extension\\(\"txt\"\\)"
---

<objective>
Implement backend transcription command that calls OpenAI Whisper API, saves transcript as .txt file, and returns structured transcript data.

Purpose: Provide secure, async audio transcription via Tauri command with proper error handling and sidecar file storage.
Output: New `transcribe_audio` command registered and callable from frontend.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-transcription-mvp/01-RESEARCH.md
@.planning/phases/01-transcription-mvp/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create transcription command module</name>
  <files>src-tauri/src/commands/transcription.rs</files>
  <action>
    Create directory `src-tauri/src/commands/` if it doesn't exist.
    Create file `src-tauri/src/commands/transcription.rs` with the following content:
    
    ```rust
    use async_openai::{
        config::OpenAIConfig,
        types::{
            CreateTranscriptionRequestArgs,
            TimestampGranularity,
            TranscriptionResponseFormat,
        },
        Client,
    };
    use serde::{Deserialize, Serialize};
    use std::fs::File;
    use std::path::PathBuf;
    use thiserror::Error;
    
    #[derive(Debug, Serialize, Deserialize)]
    pub struct WordTimestamp {
        pub word: String,
        pub start: f32,
        pub end: f32,
    }
    
    #[derive(Debug, Serialize, Deserialize)]
    pub struct Transcript {
        pub text: String,
        pub words: Vec<WordTimestamp>,
        pub duration: f32,
        pub language: String,
    }
    
    #[derive(Debug, Error)]
    pub enum TranscriptionError {
        #[error("Missing API key: OPENAI_API_KEY environment variable not set")]
        MissingApiKey,
        #[error("Failed to read file: {0}")]
        FileError(String),
        #[error("OpenAI API error: {0}")]
        ApiError(String),
        #[error("Invalid request: {0}")]
        RequestError(String),
        #[error("Failed to save transcript: {0}")]
        SaveError(String),
    }
    
    impl From<std::io::Error> for TranscriptionError {
        fn from(err: std::io::Error) -> Self {
            TranscriptionError::FileError(err.to_string())
        }
    }
    
    impl From<async_openai::error::OpenAIError> for TranscriptionError {
        fn from(err: async_openai::error::OpenAIError) -> Self {
            TranscriptionError::ApiError(err.to_string())
        }
    }
    
    #[tauri::command]
    pub async fn transcribe_audio(path: PathBuf) -> Result<Transcript, String> {
        transcribe_audio_inner(path).await.map_err(|e| e.to_string())
    }
    
    async fn transcribe_audio_inner(path: PathBuf) -> Result<Transcript, TranscriptionError> {
        let api_key = std::env::var("OPENAI_API_KEY")
            .map_err(|_| TranscriptionError::MissingApiKey)?;
        
        let config = OpenAIConfig::new().with_api_key(&api_key);
        let client = Client::with_config(config);
        
        // Validate file size (25 MB limit)
        let metadata = std::fs::metadata(&path)?;
        if metadata.len() > 25 * 1024 * 1024 {
            return Err(TranscriptionError::FileError(
                "File size exceeds 25 MB limit".to_string(),
            ));
        }
        
        let file = File::open(&path)?;
        
        let request = CreateTranscriptionRequestArgs::default()
            .file(file)
            .model("gpt-4o-transcribe")
            .response_format(TranscriptionResponseFormat::VerboseJson)
            .timestamp_granularities(&[TimestampGranularity::Word])
            .build()
            .map_err(|e| TranscriptionError::RequestError(e.to_string()))?;
        
        let response = client
            .audio()
            .transcriptions()
            .create(request)
            .await?;
        
        // Extract words from response (words field is available in verbose_json)
        let words = response
            .words
            .unwrap_or_default()
            .into_iter()
            .map(|w| WordTimestamp {
                word: w.word,
                start: w.start,
                end: w.end,
            })
            .collect();
        
        // Save transcript as .txt file alongside original audio
        let transcript_path = path.with_extension("txt");
        std::fs::write(&transcript_path, &response.text)
            .map_err(|e| TranscriptionError::SaveError(e.to_string()))?;
        
        Ok(Transcript {
            text: response.text,
            words,
            duration: response.duration.unwrap_or(0.0),
            language: response.language.unwrap_or_else(|| "unknown".to_string()),
        })
    }
    ```
    
    **Why:** Centralized command with comprehensive error handling, file size validation, and sidecar file saving.
  </action>
  <verify>File compiles (`cargo check` passes)</verify>
  <done>Transcription command module exists with all required functionality</done>
</task>

<task type="auto">
  <name>Task 2: Register command in lib.rs</name>
  <files>src-tauri/src/lib.rs</files>
  <action>
    Import the transcription module and add its command to the invoke handler.
    
    1. At the top of `lib.rs`, after existing imports, add:
    
    ```rust
    mod commands;
    ```
    
    2. Inside the `invoke_handler` macro, add `commands::transcription::transcribe_audio`:
    
    ```rust
    .invoke_handler(tauri::generate_handler![
        pick_folder,
        scan_folder_for_audio,
        read_file_meta,
        commands::transcription::transcribe_audio
    ])
    ```
    
    3. Ensure the `commands` module is accessible (if `src-tauri/src/commands/mod.rs` doesn't exist, create it with `pub mod transcription;`).
    
    **Why:** Integrates the new command into Tauri's IPC system, making it callable from frontend.
  </action>
  <verify>Rust project compiles without errors; command appears in generated handler</verify>
  <done>Command registered and invokable via `invoke('transcribe_audio', ...)`</done>
</task>

<task type="auto">
  <name>Task 3: Test command with a dummy audio file</name>
  <files>src-tauri/src/commands/transcription.rs</files>
  <action>
    Verify the command works by running a simple integration test (optional but recommended).
    
    Steps:
    1. Set `OPENAI_API_KEY` environment variable (skip if not available).
    2. Create a small test script or use `cargo test` to ensure compilation.
    3. If API key is present, test with a small audio file (e.g., 5-second MP3) and confirm transcript file creation.
    
    **Note:** If API key is missing, the command will return a user‑friendly error; that's acceptable for now.
    
    **Why:** Early validation prevents downstream integration issues.
  </action>
  <verify>Command compiles and responds to invocation (error or success)</verify>
  <done>Transcription command is functional and returns appropriate errors</done>
</task>

</tasks>

<verification>
- Run `cargo build` in `src-tauri/` – builds successfully.
- Check that `OPENAI_API_KEY` environment variable is read (if set).
- Invoke command from frontend test harness or Tauri devtools to confirm IPC works.
</verification>

<success_criteria>
1. `src-tauri/src/commands/transcription.rs` exists with full implementation.
2. `src-tauri/src/lib.rs` registers `transcribe_audio` command.
3. Command can be invoked and returns either transcript or meaningful error.
4. Sidecar `.txt` file is created next to audio file when transcription succeeds.
</success_criteria>

<output>
After completion, create `.planning/phases/01-transcription-mvp/01-02-SUMMARY.md`
</output>