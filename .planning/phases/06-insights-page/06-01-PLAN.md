---
phase: 06-insights-page
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/fs/config.ts
  - src/components/RecordingsTable.tsx
  - src/components/RecordingsList.tsx
autonomous: true

must_haves:
  truths:
    - "When a user transcribes a recording, the app persists transcription metadata (at least language + timestamps) locally."
    - "The Insights feature can read a map of per-recording transcription metadata keyed by audio path."
  artifacts:
    - path: "src/lib/fs/config.ts"
      provides: "Store-backed helpers for transcription metadata"
    - path: "src/components/RecordingsTable.tsx"
      provides: "Writes transcription metadata after successful transcription"
  key_links:
    - from: "src/components/RecordingsTable.tsx"
      to: "src/lib/fs/config.ts"
      via: "setTranscriptionMeta() after transcribeAudio()"
      pattern: "setTranscriptionMeta\(.*language"
    - from: "src/components/RecordingsList.tsx"
      to: "src/lib/fs/config.ts"
      via: "setTranscriptionMeta() after transcribeAudio/transcribeAudioBatch"
      pattern: "setTranscriptionMeta\("
---

<objective>
Persist per-recording transcription metadata (language + durations) so the Insights dashboard can produce language distribution and accurate transcription totals.

Purpose: The current transcript sidecar `.txt` does not contain language; we need a persisted metadata source to power INSIGHTS-03.
Output: Store-backed transcription metadata helpers and UI wiring to populate them when transcriptions run.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/lib/fs/config.ts
@src/components/RecordingsTable.tsx
@src/components/RecordingsList.tsx
@src/lib/transcription/commands.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add store-backed transcription metadata helpers</name>
  <files>src/lib/fs/config.ts</files>
  <action>
Extend the existing store wrapper (`config.json`) with transcription metadata storage.

Implement:
- A `TranscriptionMeta` type with fields:
  - `language: string`
  - `transcribedAt: number` (unix ms)
  - `transcriptionSeconds?: number` (Whisper duration)
  - `audioSeconds?: number` (AudioItem.duration snapshot)
- `getTranscriptionMeta(audioPath: string): Promise<TranscriptionMeta | null>`
- `setTranscriptionMeta(audioPath: string, meta: TranscriptionMeta): Promise<void>`
- `getAllTranscriptionMeta(): Promise<Record<string, TranscriptionMeta>>` (returns empty object when missing)

Storage:
- Use a single store key: `transcriptionMetaByPath`.
- Keys inside that object are the full audio path strings.
- Always call `save()` after writes.

Keep existing exports and behavior intact (`getLastFolder`, editor state, editor actions completion).
  </action>
  <verify>Type-check: `npm run build` succeeds and `src/lib/fs/config.ts` exports the 3 helpers and `TranscriptionMeta`.</verify>
  <done>Transcription metadata can be read/written via the config store under `transcriptionMetaByPath`.</done>
</task>

<task type="auto">
  <name>Task 2: Persist metadata on transcription completion (single + batch)</name>
  <files>src/components/RecordingsTable.tsx, src/components/RecordingsList.tsx</files>
  <action>
Wire the transcription UI to persist metadata after a successful transcription.

`src/components/RecordingsTable.tsx`:
- Import `setTranscriptionMeta` from `src/lib/fs/config.ts`.
- When `transcribeAudio(recording.path)` resolves, immediately call `setTranscriptionMeta(recording.path, { ... })` using:
  - `language`: `transcript.language` (fallback to `'unknown'` if falsy)
  - `transcribedAt`: `Date.now()`
  - `transcriptionSeconds`: `transcript.duration`
  - `audioSeconds`: `recording.duration`
- When opening an existing transcript (the `existingTranscript` branch), also write metadata if useful:
  - language: `'unknown'`
  - transcriptionSeconds: `recording.duration ?? 0`
  - audioSeconds: `recording.duration`

`src/components/RecordingsList.tsx`:
- Import `setTranscriptionMeta`.
- In `handleTranscribe`, after success, persist metadata using the same shape as above.
- In batch transcription flow, for each successful transcript result, persist metadata for that recording path.

Do not change the `.txt` sidecar behavior; only add store metadata writes.
  </action>
  <verify>Build: `npm run build` succeeds with the new imports and calls.</verify>
  <done>New transcriptions result in stored `language` + duration metadata available to the Insights page.</done>
</task>

</tasks>

<verification>
- Store helpers exist and do not break existing config usage.
- Transcription flows write metadata without changing transcript save/read behavior.
</verification>

<success_criteria>
- New transcriptions persist `language` and durations in the store.
- A single call can retrieve all transcription metadata by audio path.
</success_criteria>

<output>
After completion, create `.planning/phases/06-insights-page/06-01-SUMMARY.md`
</output>
