---
phase: 02-transcript-management-enhancements
plan: 06
type: execute
wave: 5
depends_on: []
files_modified:
  - src-tauri/src/commands/transcription.rs
  - src/lib/transcription/commands.ts
  - src/components/TranscriptionModal.tsx
autonomous: true
must_haves:
  truths:
    - "App generates AI summary of transcript content"
  artifacts:
    - path: "src-tauri/src/commands/transcription.rs"
      provides: "AI summary generation command"
      contains: "summarize_transcript"
    - path: "src/lib/transcription/commands.ts"
      provides: "Frontend wrapper for summary command"
      contains: "summarizeTranscript"
    - path: "src/components/TranscriptionModal.tsx"
      provides: "Summary button and display"
      contains: "summary"
  key_links:
    - from: "src/components/TranscriptionModal.tsx"
      to: "src/lib/transcription/commands.ts"
      via: "summarizeTranscript import and call"
      pattern: "summarizeTranscript"
    - from: "src-tauri/src/commands/transcription.rs::summarize_transcript"
      to: "async_openai::chat"
      via: "OpenAI ChatCompletion"
      pattern: "create_chat_completion"
---

<objective>
Add AI‑powered summarization of transcripts using OpenAI's chat models.

Purpose: Help users quickly grasp the main points of long recordings without reading the full transcript.
Output: "Summarize" button in TranscriptionModal, backend command calling GPT, summary display.
</objective>

<execution_context>
@~/.opencode/get-shit-done/workflows/execute-plan.md
@~/.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Existing OpenAI integration and transcript structure
@src-tauri/src/commands/transcription.rs
@src/lib/transcription/types.ts
</context>

<tasks>

<task type="auto">
<name>Task 1: Add backend command to generate summary</name>
<files>src-tauri/src/commands/transcription.rs</files>
<action>
1. Add a new public function `summarize_transcript` with #[tauri::command] attribute.
   - Signature: `async fn summarize_transcript(text: String) -> Result<String, String>`
   - Takes transcript text as input, returns summary string.
2. Implementation:
   - Use existing OpenAI client (same as transcription) but call ChatCompletion API.
   - Model: `gpt-3.5-turbo` (or `gpt-4o-mini` for cost efficiency).
   - Prompt: "Summarize the following transcript in 3‑5 bullet points. Focus on key points, decisions, and action items. Transcript:\n\n{text}"
   - Parse response content and return.
   - Error handling: map OpenAI errors to user‑friendly strings.
3. Register command in `src-tauri/src/lib.rs` invoke_handler.
4. Ensure API key is present (same OPENAI_API_KEY).
</action>
<verify>
- Compile Rust project (`cargo check`).
- Test command with a sample transcript text (via Tauri devtools).
- Verify summary returned.
</verify>
<done>
Summary command compiles, registered, and can generate bullet‑point summaries from transcript text.
</done>
</task>

<task type="auto">
<name>Task 2: Add summary UI to TranscriptionModal</name>
<files>src/components/TranscriptionModal.tsx, src/lib/transcription/commands.ts</files>
<action>
1. In `src/lib/transcription/commands.ts`, add wrapper:
   ```
   export async function summarizeTranscript(text: string): Promise<string> {
     return invoke('summarize_transcript', { text })
   }
   ```
2. In TranscriptionModal:
   - Add state `summary` (string) and `loadingSummary` (boolean).
   - Add a "Summarize" button next to other action buttons.
   - On click: set loadingSummary true, call summarizeTranscript(transcript.text), store result, set loadingSummary false.
   - Display summary below plain text block (or in expandable section).
   - Style summary with bullet points, distinct background.
   - Show loading spinner while generating.
3. Consider caching summary per transcript to avoid repeated API calls.
</action>
<verify>
- Open transcript modal for a transcribed recording.
- Click "Summarize" button, see loading indicator.
- After a few seconds, summary appears below transcript.
- Verify summary is coherent bullet points.
</verify>
<done>
TranscriptionModal has working summarization button that displays AI‑generated summary.
</done>
</task>

<task type="auto">
<name>Task 3: Enhance summary UX with error handling and options</name>
<files>src/components/TranscriptionModal.tsx</files>
<action>
1. Add error handling: if summary generation fails, show toast error.
2. Add ability to regenerate summary (refresh button).
3. Optionally add summary length options (short, medium, long) via dropdown.
4. Style summary section with heading "AI Summary" and a subtle border.
5. Ensure summary is scrollable if long.

Considerations:
- Rate limiting: avoid spamming API; disable button while loading.
- Cost transparency: maybe show estimated token count? Not needed for now.
</action>
<verify>
- Test with various transcript lengths (short, long).
- Test error case (e.g., no API key).
- Verify UI responds appropriately.
</verify>
<done>
Summary feature is robust, handles errors, and provides good user experience.
</done>
</task>

</tasks>

<verification>
1. Transcribe a recording with substantial content (meeting, interview).
2. Open transcript modal, click "Summarize".
3. Wait for API call, observe summary appears.
4. Verify summary captures key points.
5. Test with empty transcript (should handle gracefully).
</verification>

<success_criteria>
- User can generate AI summary with one click.
- Summary is concise and relevant.
- Error states are handled gracefully.
- No regression to existing functionality.
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcript-management-enhancements/02-06-SUMMARY.md`
</output>